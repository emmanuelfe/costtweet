{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fasttext needs 10 minutes to be loaded\n",
    "C'est le temps de chargement du dataset fasttextwiki.fr.vec donne un vocabulaire de 1 115 449 mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\code\\ml\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens: 1152449\n"
     ]
    }
   ],
   "source": [
    "#https://blog.manash.me/how-to-use-pre-trained-word-vectors-from-facebooks-fasttext-a71e6d55f27\n",
    "from __future__ import print_function\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Creating the model\n",
    "en_model = KeyedVectors.load_word2vec_format('./fasttextwiki.fr.vec')\n",
    "\n",
    "# Getting the tokens \n",
    "words = []\n",
    "for word in en_model.vocab:\n",
    "    words.append(word)\n",
    "\n",
    "# Printing out number of tokens available\n",
    "print(\"Number of Tokens: {}\".format(len(words)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of a word vector: 300\n",
      "Vector components of a word: [ 0.28556    0.14918   -0.42066   -0.018017   0.22033   -0.014212\n",
      " -0.22482   -0.14634   -0.2699     0.098651  -0.050317   0.10059\n",
      " -0.026137   0.37153    0.29702    0.047411  -0.088056  -0.16456\n",
      " -0.12686   -0.49784    0.038195   0.0413    -0.1882     0.18333\n",
      " -0.10767   -0.32023    0.29278   -0.23128   -0.21992   -0.32003\n",
      " -0.03499    0.057215   0.24078    0.26596   -0.22592    0.01992\n",
      "  0.3365    -0.21083    0.26889    0.40077    0.21776    0.22067\n",
      "  0.18016   -0.049212  -0.008983   0.016028   0.11793   -0.35693\n",
      " -0.069114   0.38563    0.17778    0.31749   -0.42457   -0.056504\n",
      "  0.15986    0.17301   -0.11133    0.49019   -0.087131  -0.3636\n",
      " -0.1533    -0.084371  -0.091876  -0.37395   -0.023514   0.20364\n",
      "  0.19245   -0.37532   -0.13406    0.063893  -0.1126    -0.046767\n",
      " -0.1987     0.24293   -0.47214   -0.12061    0.087109   0.40284\n",
      "  0.35148    0.029822   0.022778   0.17187    0.2687     0.10117\n",
      "  0.17393    0.38146    0.065566   0.3744     0.12063   -0.32738\n",
      " -0.36659    0.25641   -0.18834   -0.035187  -0.17785   -0.13979\n",
      "  0.30206   -0.085775   0.037413  -0.35929    0.38164    0.24672\n",
      " -0.033128   0.10896    0.080853  -0.16726    0.21757   -0.23939\n",
      "  0.3013    -0.28519   -0.020924   0.2629    -0.23369   -0.013965\n",
      "  0.33976   -0.26566   -0.097942  -0.11281    0.136      0.29089\n",
      " -0.38622    0.065744  -0.51822    0.058855  -0.047079  -0.23249\n",
      "  0.27628    0.016734  -0.0081994  0.26016    0.012989   0.043613\n",
      "  0.31178    0.11754   -0.008928   0.072615  -0.10836    0.092818\n",
      " -0.30108    0.014703  -0.44886    0.11617   -0.097613   0.052013\n",
      " -0.51354    0.59334   -0.37651    0.33515    0.12068    0.18905\n",
      "  0.34734    0.42929   -0.086322   0.11406   -0.37693   -0.18121\n",
      "  0.068265  -0.21104    0.27073    0.16361   -0.28491   -0.65746\n",
      "  0.059344   0.3698    -0.4288     0.089888   0.16549   -0.03272\n",
      " -0.22489   -0.092452  -0.3059    -0.28396   -0.10987    0.30787\n",
      " -0.20383   -0.11593    0.24732    0.072244   0.4988    -0.59873\n",
      " -0.47288   -0.33072    0.14349    0.37956    0.30701    0.084332\n",
      " -0.16637   -0.34572    0.32613   -0.045468  -0.2781     0.51973\n",
      "  0.016158   0.34261    0.46744   -0.029338   0.33534   -0.2388\n",
      " -0.3057     0.0049257 -0.08767    0.14749   -0.094305  -0.01446\n",
      " -0.41231   -0.52174    0.30756    0.49899   -0.12631   -0.11456\n",
      " -0.34148   -0.21906   -0.083196  -0.26285   -0.35046   -0.21058\n",
      " -0.02783    0.10863   -0.33375   -0.070348  -0.35486    0.0059225\n",
      "  0.031773  -0.028421   0.023332   0.070761   0.22479   -0.57596\n",
      "  0.11158    0.035421   0.043721   0.58838   -0.12993   -0.28281\n",
      " -0.34964    0.52865   -0.12253   -0.37915    0.55358   -0.085896\n",
      "  0.04821   -0.038955   0.043028   0.29477   -0.038482  -0.081317\n",
      "  0.073853  -0.25637    0.19329    0.54768    0.18854    0.12177\n",
      " -0.11684   -0.16962    0.33305   -0.12043   -0.14997   -0.078914\n",
      " -0.16876    0.26092   -0.41547   -0.10901    0.077592   0.061466\n",
      " -0.1652     0.34514    0.23426   -0.098729   0.035415  -0.019383\n",
      " -0.029231   0.018437   0.063323   0.25403   -0.36029   -0.21835\n",
      " -0.1603     0.058724  -0.224      0.15384    0.21513    0.47991\n",
      "  0.45671   -0.29218   -0.22102    0.25835    0.21553    0.041272\n",
      "  0.36664   -0.073513   0.40173    0.24624    0.088466   0.010223\n",
      " -0.2461    -0.22905    0.2563     0.031837  -0.029245   0.012347 ]\n",
      "Word: montparnasse,, Similarity: 0.96\n",
      "Word: montparnasse », Similarity: 0.90\n",
      "Word: montparnos, Similarity: 0.89\n",
      "Word: montparnasse/saint, Similarity: 0.85\n",
      "Word: montpantier, Similarity: 0.65\n",
      "Word: montpalau, Similarity: 0.61\n",
      "Word: montmartre, Similarity: 0.60\n",
      "Word: gaîté, Similarity: 0.59\n",
      "Word: biblioparnasse, Similarity: 0.58\n",
      "Word: lachaise, Similarity: 0.57\n"
     ]
    }
   ],
   "source": [
    "# Printing out the dimension of a word vector \n",
    "print(\"Dimension of a word vector: {}\".format(\n",
    "    len(en_model[words[0]])\n",
    "))\n",
    "\n",
    "# Print out the vector of a word \n",
    "print(\"Vector components of a word: {}\".format(\n",
    "    en_model[words[0]]\n",
    "))\n",
    "\n",
    "# Pick a word \n",
    "find_similar_to = 'montparnasse'\n",
    "\n",
    "# Finding out similar words [default= top 10]\n",
    "for similar_word in en_model.similar_by_word(find_similar_to):\n",
    "    print(\"Word: {0}, Similarity: {1:.2f}\".format(\n",
    "        similar_word[0], similar_word[1]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: champery, Similarity: 0.73\n",
      "Word: champeron, Similarity: 0.68\n",
      "Word: champeroux, Similarity: 0.66\n",
      "Word: pc_ratp_station, Similarity: 0.65\n",
      "Word: cardinet, Similarity: 0.65\n",
      "Word: clignancourt, Similarity: 0.65\n",
      "Word: champerboux, Similarity: 0.65\n",
      "Word: charonne, Similarity: 0.62\n",
      "Word: champereia, Similarity: 0.62\n",
      "Word: denfert, Similarity: 0.62\n"
     ]
    }
   ],
   "source": [
    "# Pick a word \n",
    "find_similar_to = 'champerret'\n",
    "\n",
    "# Finding out similar words [default= top 10]\n",
    "for similar_word in en_model.similar_by_word(find_similar_to):\n",
    "    print(\"Word: {0}, Similarity: {1:.2f}\".format(\n",
    "        similar_word[0], similar_word[1]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word : perret , Similarity: 0.37\n",
      "Word : duperret , Similarity: 0.36\n",
      "Word : euratlas , Similarity: 0.35\n",
      "Word : station_métro , Similarity: 0.33\n",
      "Word : djazaïr , Similarity: 0.31\n",
      "Word : denfert , Similarity: 0.30\n",
      "Word : boulevards , Similarity: 0.29\n",
      "Word : haussmannien , Similarity: 0.29\n",
      "Word : quai , Similarity: 0.29\n",
      "Word : bab , Similarity: 0.29\n"
     ]
    }
   ],
   "source": [
    "# Test words \n",
    "word_add = ['champerret']\n",
    "word_sub = ['champery']\n",
    "\n",
    "# Word vector addition and subtraction \n",
    "for resultant_word in en_model.most_similar(\n",
    "    positive=word_add, negative=word_sub\n",
    "):\n",
    "    print(\"Word : {0} , Similarity: {1:.2f}\".format(\n",
    "        resultant_word[0], resultant_word[1]\n",
    "    ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
